{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåü Enriquecimiento de Datos con IA\n",
    "\n",
    "Este notebook muestra c√≥mo podemos utilizar la IA generativa para enriquecer nuestros datos, generar nuevas caracter√≠sticas y obtener insights adicionales.\n",
    "\n",
    "## ¬øQu√© aprender√°s?\n",
    "- üîç Enriquecer datasets existentes con descripciones generadas por IA\n",
    "- üè∑Ô∏è Clasificar autom√°ticamente textos y categor√≠as\n",
    "- üß™ Generar datos sint√©ticos para pruebas o entrenamiento\n",
    "- üí° Extraer insights autom√°ticamente a partir de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Importamos las bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Instalamos las bibliotecas necesarias (descomenta si es necesario)\n",
    "# !pip install openai python-dotenv pandas seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Importamos las bibliotecas\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import time  # Para a√±adir pausas entre llamadas a la API\n",
    "\n",
    "# Configuraci√≥n para visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set(font_scale=1.2)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Configuraci√≥n de la API de OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cargamos la API key desde el archivo .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Verificamos y configuramos la API\n",
    "if api_key is None or api_key == \"tu_api_key_aqui\":\n",
    "    print(\"‚ö†Ô∏è ERROR: API key no configurada correctamente.\")\n",
    "    print(\"Por favor, crea un archivo .env con tu OPENAI_API_KEY.\")\n",
    "else:\n",
    "    print(\"‚úÖ API key cargada correctamente.\")\n",
    "    # Configuramos la biblioteca con la API key\n",
    "    openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Funci√≥n para hacer peticiones a la API de OpenAI\n",
    "def consultar_openai(prompt, modelo=\"gpt-3.5-turbo\", temperatura=0.7, max_tokens=150, formato_salida=None):\n",
    "    \"\"\"Realiza una consulta a la API de OpenAI\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): El texto de entrada para el modelo\n",
    "        modelo (str): El modelo a utilizar\n",
    "        temperatura (float): Controla la creatividad (0.0 a 1.0)\n",
    "        max_tokens (int): Longitud m√°xima de la respuesta\n",
    "        formato_salida (str): Si se requiere un formato espec√≠fico (json, lista, etc.)\n",
    "        \n",
    "    Returns:\n",
    "        str o dict: El texto generado o un objeto JSON si se solicit√≥\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # A√±adimos instrucciones de formato si es necesario\n",
    "        if formato_salida == \"json\":\n",
    "            prompt += \"\\n\\nDevuelve la respuesta en formato JSON v√°lido.\"\n",
    "            response_format = {\"type\": \"json_object\"}\n",
    "        else:\n",
    "            response_format = None\n",
    "            \n",
    "        # Creamos la petici√≥n al API\n",
    "        response = openai.chat.completions.create(\n",
    "            model=modelo,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperatura,\n",
    "            max_tokens=max_tokens,\n",
    "            response_format=response_format\n",
    "        )\n",
    "        \n",
    "        # Extraemos el texto generado\n",
    "        respuesta = response.choices[0].message.content\n",
    "        \n",
    "        # Si se solicit√≥ JSON, convertimos la respuesta a un diccionario\n",
    "        if formato_salida == \"json\":\n",
    "            try:\n",
    "                return json.loads(respuesta)\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"‚ö†Ô∏è Advertencia: No se pudo decodificar el JSON. Devolviendo texto plano.\")\n",
    "                return respuesta\n",
    "        else:\n",
    "            return respuesta\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üêß Cargamos el Dataset de Ping√ºinos\n",
    "\n",
    "Vamos a utilizar el dataset de ping√ºinos de Seaborn, que contiene informaci√≥n sobre diferentes especies de ping√ºinos en la Ant√°rtida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cargamos el dataset de ping√ºinos\n",
    "penguins = sns.load_dataset(\"penguins\")\n",
    "\n",
    "# Mostramos las primeras filas\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exploramos informaci√≥n b√°sica del dataset\n",
    "print(f\"N√∫mero de filas: {penguins.shape[0]}\")\n",
    "print(f\"N√∫mero de columnas: {penguins.shape[1]}\")\n",
    "print(f\"Especies de ping√ºinos: {penguins['species'].unique()}\")\n",
    "print(f\"Islas: {penguins['island'].unique()}\")\n",
    "\n",
    "# Verificamos valores nulos\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(penguins.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Eliminamos filas con valores nulos para este ejemplo\n",
    "penguins_clean = penguins.dropna().reset_index(drop=True)\n",
    "print(f\"Dataset limpio: {penguins_clean.shape[0]} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Enriquecimiento 1: Generar Descripciones Detalladas\n",
    "\n",
    "Vamos a usar la IA para generar descripciones detalladas para cada especie de ping√ºino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Obtenemos las especies √∫nicas\n",
    "especies = penguins_clean['species'].unique()\n",
    "print(f\"Especies a describir: {especies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Funci√≥n para generar descripci√≥n de una especie\n",
    "def generar_descripcion_especie(especie):\n",
    "    prompt = f\"\"\"\n",
    "    Genera una descripci√≥n detallada del ping√ºino {especie} que incluya:\n",
    "    1. Caracter√≠sticas f√≠sicas principales\n",
    "    2. H√°bitat y distribuci√≥n geogr√°fica\n",
    "    3. Comportamiento y alimentaci√≥n\n",
    "    4. Estado de conservaci√≥n\n",
    "    \n",
    "    Formato: p√°rrafo conciso de 100-150 palabras.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Llamamos a la API\n",
    "    return consultar_openai(prompt, temperatura=0.7, max_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generamos descripciones para cada especie\n",
    "descripciones = {}\n",
    "\n",
    "for especie in especies:\n",
    "    print(f\"Generando descripci√≥n para: {especie}...\")\n",
    "    descripciones[especie] = generar_descripcion_especie(especie)\n",
    "    print(f\"‚úÖ Descripci√≥n generada\")\n",
    "    # Pausa para evitar l√≠mites de tasa en la API\n",
    "    time.sleep(1)\n",
    "\n",
    "# Mostramos las descripciones\n",
    "for especie, descripcion in descripciones.items():\n",
    "    print(f\"\\nüêß {especie.upper()}:\\n\")\n",
    "    print(descripcion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Enriquecimiento 2: Clasificaci√≥n Autom√°tica\n",
    "\n",
    "Vamos a usar la IA para clasificar a los ping√ºinos en categor√≠as de tama√±o basadas en sus medidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Seleccionamos una muestra para trabajar (10 ping√ºinos)\n",
    "muestra_ping√ºinos = penguins_clean.sample(10, random_state=42).reset_index(drop=True)\n",
    "muestra_ping√ºinos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Funci√≥n para clasificar el tama√±o del ping√ºino basado en sus medidas\n",
    "def clasificar_tama√±o(fila):\n",
    "    prompt = f\"\"\"\n",
    "    Basado en las siguientes medidas de un ping√ºino {fila['species']}, clasif√≠calo en una categor√≠a de tama√±o (Peque√±o, Mediano, Grande):\n",
    "    - Longitud del pico: {fila['bill_length_mm']} mm\n",
    "    - Profundidad del pico: {fila['bill_depth_mm']} mm\n",
    "    - Longitud de la aleta: {fila['flipper_length_mm']} mm\n",
    "    - Masa corporal: {fila['body_mass_g']} g\n",
    "    \n",
    "    Devuelve solo una palabra: Peque√±o, Mediano o Grande.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Llamamos a la API con baja temperatura para respuestas consistentes\n",
    "    return consultar_openai(prompt, temperatura=0.1, max_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clasificamos cada ping√ºino en la muestra\n",
    "categorias_tama√±o = []\n",
    "\n",
    "for idx, fila in muestra_ping√ºinos.iterrows():\n",
    "    print(f\"Clasificando ping√ºino {idx+1}/10...\")\n",
    "    categoria = clasificar_tama√±o(fila)\n",
    "    categorias_tama√±o.append(categoria.strip())\n",
    "    # Pausa para evitar l√≠mites de tasa en la API\n",
    "    time.sleep(1)\n",
    "\n",
    "# A√±adimos la categor√≠a al dataframe\n",
    "muestra_ping√ºinos['categoria_tama√±o'] = categorias_tama√±o\n",
    "\n",
    "# Mostramos el resultado\n",
    "muestra_ping√ºinos[['species', 'body_mass_g', 'flipper_length_mm', 'categoria_tama√±o']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualizamos la distribuci√≥n de categor√≠as\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='categoria_tama√±o', hue='species', data=muestra_ping√ºinos, palette='viridis')\n",
    "plt.title('Categor√≠as de Tama√±o por Especie', fontsize=15)\n",
    "plt.xlabel('Categor√≠a de Tama√±o', fontsize=12)\n",
    "plt.ylabel('Cantidad', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Enriquecimiento 3: Generaci√≥n de Datos Sint√©ticos\n",
    "\n",
    "Vamos a utilizar la IA para generar datos de ping√ºinos sint√©ticos basados en los patrones del dataset original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Primero, obtenemos un resumen estad√≠stico del dataset\n",
    "resumen = penguins_clean.groupby('species').agg({\n",
    "    'bill_length_mm': ['mean', 'min', 'max'],\n",
    "    'bill_depth_mm': ['mean', 'min', 'max'],\n",
    "    'flipper_length_mm': ['mean', 'min', 'max'],\n",
    "    'body_mass_g': ['mean', 'min', 'max']\n",
    "}).round(2)\n",
    "\n",
    "# Mostramos el resumen\n",
    "resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Funci√≥n para generar ping√ºinos sint√©ticos\n",
    "def generar_ping√ºinos_sinteticos(n=5):\n",
    "    # Convertimos el resumen a formato de texto para el prompt\n",
    "    resumen_texto = \"\"\n",
    "    for especie in especies:\n",
    "        resumen_texto += f\"\\n{especie}:\\n\"\n",
    "        for medida in ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']:\n",
    "            media = resumen.loc[especie, (medida, 'mean')]\n",
    "            minimo = resumen.loc[especie, (medida, 'min')]\n",
    "            maximo = resumen.loc[especie, (medida, 'max')]\n",
    "            resumen_texto += f\"- {medida}: media={media}, rango=[{minimo}-{maximo}]\\n\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Genera {n} ping√ºinos sint√©ticos basados en las siguientes estad√≠sticas de ping√ºinos reales.\n",
    "    Aseg√∫rate de que los valores sean realistas y dentro de los rangos t√≠picos para cada especie.\n",
    "    \n",
    "    Estad√≠sticas por especie:\n",
    "    {resumen_texto}\n",
    "    \n",
    "    Para cada ping√ºino, genera:\n",
    "    1. species: Adelie, Chinstrap, o Gentoo\n",
    "    2. island: Biscoe, Dream, o Torgersen\n",
    "    3. bill_length_mm: longitud del pico en mm\n",
    "    4. bill_depth_mm: profundidad del pico en mm\n",
    "    5. flipper_length_mm: longitud de la aleta en mm\n",
    "    6. body_mass_g: masa corporal en gramos\n",
    "    7. sex: male o female\n",
    "    \n",
    "    Devuelve un array de {n} objetos JSON, uno por cada ping√ºino generado.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Llamamos a la API solicitando formato JSON\n",
    "    resultado = consultar_openai(prompt, temperatura=0.8, max_tokens=500, formato_salida=\"json\")\n",
    "    \n",
    "    # Si recibimos un diccionario, extraemos la lista de ping√ºinos\n",
    "    if isinstance(resultado, dict) and 'ping√ºinos' in resultado:\n",
    "        return resultado['ping√ºinos']\n",
    "    elif isinstance(resultado, list):\n",
    "        return resultado\n",
    "    else:\n",
    "        # Intentamos extraer manualmente el JSON si no se devolvi√≥ correctamente\n",
    "        try:\n",
    "            texto = str(resultado)\n",
    "            # Buscamos el primer [ y el √∫ltimo ]\n",
    "            inicio = texto.find('[')\n",
    "            fin = texto.rfind(']') + 1\n",
    "            if inicio >= 0 and fin > inicio:\n",
    "                json_text = texto[inicio:fin]\n",
    "                return json.loads(json_text)\n",
    "            else:\n",
    "                print(\"‚ùå No se pudo extraer JSON de la respuesta.\")\n",
    "                return []\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error al procesar JSON: {e}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generamos 5 ping√ºinos sint√©ticos\n",
    "print(\"Generando ping√ºinos sint√©ticos...\")\n",
    "ping√ºinos_sinteticos = generar_ping√ºinos_sinteticos(n=5)\n",
    "\n",
    "# Convertimos a DataFrame\n",
    "if ping√ºinos_sinteticos:\n",
    "    df_sinteticos = pd.DataFrame(ping√ºinos_sinteticos)\n",
    "    print(\"\\n‚úÖ Ping√ºinos sint√©ticos generados:\")\n",
    "    display(df_sinteticos)\n",
    "else:\n",
    "    print(\"‚ùå No se pudieron generar ping√ºinos sint√©ticos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Enriquecimiento 4: Extracci√≥n de Insights\n",
    "\n",
    "Vamos a pedirle a la IA que analice nuestros datos y extraiga insights interesantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generamos un resumen de los datos para el prompt\n",
    "correlaciones = penguins_clean.corr().round(2)\n",
    "conteo_especies = penguins_clean['species'].value_counts()\n",
    "conteo_islas = penguins_clean.groupby(['island', 'species']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculamos medias por especie para cada medida\n",
    "medias_por_especie = penguins_clean.groupby('species').mean().round(2)\n",
    "\n",
    "# Resumen de datos en formato texto\n",
    "resumen_datos = f\"\"\"\n",
    "RESUMEN DEL DATASET DE PING√úINOS:\n",
    "\n",
    "1. Distribuci√≥n de especies:\n",
    "{conteo_especies.to_string()}\n",
    "\n",
    "2. Distribuci√≥n por isla y especie:\n",
    "{conteo_islas.to_string()}\n",
    "\n",
    "3. Medias por especie:\n",
    "{medias_por_especie.to_string()}\n",
    "\n",
    "4. Matriz de correlaci√≥n:\n",
    "{correlaciones.to_string()}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Funci√≥n para extraer insights\n",
    "def extraer_insights(resumen_datos):\n",
    "    prompt = f\"\"\"\n",
    "    Analiza el siguiente resumen de un dataset de ping√ºinos y extrae 5 insights relevantes y √∫tiles.\n",
    "    Para cada insight, proporciona:\n",
    "    1. Una descripci√≥n clara del hallazgo\n",
    "    2. Una posible explicaci√≥n biol√≥gica o ecol√≥gica\n",
    "    3. Una sugerencia de visualizaci√≥n que podr√≠a ilustrar mejor este insight\n",
    "    \n",
    "    {resumen_datos}\n",
    "    \n",
    "    Formato de respuesta: Devuelve un objeto JSON con una lista de 5 insights, cada uno con las propiedades 'hallazgo', 'explicacion' y 'visualizacion_sugerida'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Llamamos a la API solicitando formato JSON\n",
    "    return consultar_openai(prompt, temperatura=0.7, max_tokens=800, formato_salida=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extraemos insights de los datos\n",
    "print(\"Extrayendo insights de los datos...\")\n",
    "insights = extraer_insights(resumen_datos)\n",
    "\n",
    "# Mostramos los insights\n",
    "if insights and 'insights' in insights:\n",
    "    for i, insight in enumerate(insights['insights'], 1):\n",
    "        print(f\"\\n‚ú® INSIGHT {i}:\")\n",
    "        print(f\"üîç Hallazgo: {insight['hallazgo']}\")\n",
    "        print(f\"üß† Explicaci√≥n: {insight['explicacion']}\")\n",
    "        print(f\"üìä Visualizaci√≥n sugerida: {insight['visualizacion_sugerida']}\")\n",
    "else:\n",
    "    print(\"‚ùå No se pudieron extraer insights.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Implementemos una de las visualizaciones sugeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Ejemplo de visualizaci√≥n basada en uno de los insights\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Gr√°fico de dispersi√≥n con todas las medidas\n",
    "sns.scatterplot(x='flipper_length_mm', y='body_mass_g', \n",
    "                hue='species', size='bill_length_mm',\n",
    "                sizes=(20, 200), alpha=0.8, palette='viridis',\n",
    "                data=penguins_clean)\n",
    "\n",
    "plt.title('Relaci√≥n entre Longitud de Aleta, Masa Corporal y Longitud del Pico por Especie', fontsize=16)\n",
    "plt.xlabel('Longitud de Aleta (mm)', fontsize=14)\n",
    "plt.ylabel('Masa Corporal (g)', fontsize=14)\n",
    "plt.legend(title='Especie', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üå± C√≥mo la IA apoya en enriquecer flujos de datos\n",
    "\n",
    "La IA puede enriquecer tus flujos de datos de m√∫ltiples formas:\n",
    "\n",
    "### 1Ô∏è‚É£ Clasificaci√≥n de texto\n",
    "- üè∑Ô∏è Categorizaci√≥n autom√°tica de comentarios, rese√±as o documentos\n",
    "- üìä An√°lisis de sentimiento para entender la opini√≥n de clientes\n",
    "- üîç Extracci√≥n de temas y conceptos clave de grandes vol√∫menes de texto\n",
    "\n",
    "### 2Ô∏è‚É£ Generaci√≥n de datos\n",
    "- üß™ Creaci√≥n de datos sint√©ticos para pruebas o entrenamiento\n",
    "- üìù Generaci√≥n de descripciones, t√≠tulos o res√∫menes\n",
    "- üîÑ Aumento de datos para equilibrar clases subrepresentadas\n",
    "\n",
    "### 3Ô∏è‚É£ Limpieza de datos\n",
    "- üßπ Detecci√≥n y correcci√≥n de errores o valores at√≠picos\n",
    "- üîÑ Normalizaci√≥n de texto (nombres, direcciones, etc.)\n",
    "- üìã Completar valores faltantes con datos realistas\n",
    "\n",
    "### 4Ô∏è‚É£ Extracci√≥n de insights\n",
    "- üí° Descubrimiento autom√°tico de patrones y relaciones\n",
    "- üìà Generaci√≥n de hip√≥tesis para investigaci√≥n adicional\n",
    "- üìä Sugerencias de visualizaciones relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Ideas \"wow\" para demostraciones\n",
    "\n",
    "### 1Ô∏è‚É£ Clasificaci√≥n de rese√±as en vivo\n",
    "- Crear un peque√±o dashboard donde se puedan pegar rese√±as de productos\n",
    "- La IA analiza en tiempo real y clasifica por sentimiento, temas principales y problemas detectados\n",
    "- Muestra un resumen visual con gr√°ficos de temas y sentimientos\n",
    "\n",
    "### 2Ô∏è‚É£ Generaci√≥n de insights a partir de descripciones cortas\n",
    "- Permitir al usuario describir brevemente un negocio o producto\n",
    "- La IA genera autom√°ticamente:\n",
    "  - Posibles segmentos de clientes\n",
    "  - Indicadores clave de rendimiento (KPIs) relevantes\n",
    "  - Ideas para an√°lisis de datos y experimentos\n",
    "\n",
    "### 3Ô∏è‚É£ Transformaci√≥n de datos num√©ricos en narrativas\n",
    "- Cargar un dataset simple (ventas, usuarios, etc.)\n",
    "- La IA genera autom√°ticamente una narrativa que explica los patrones principales\n",
    "- Incluye recomendaciones accionables basadas en los datos\n",
    "\n",
    "### 4Ô∏è‚É£ Generador de dashboards por voz\n",
    "- El usuario describe verbalmente qu√© quiere visualizar\n",
    "- La IA genera el c√≥digo para crear ese dashboard espec√≠fico\n",
    "- Se muestra en tiempo real el resultado visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Ejemplo de integraci√≥n con dashboard\n",
    "\n",
    "Aqu√≠ un ejemplo de c√≥mo podr√≠as integrar el an√°lisis de ping√ºinos en un dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Ejemplo conceptual de c√≥digo para Streamlit (no ejecutar)\n",
    "'''\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Configuraci√≥n inicial\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "st.set_page_config(page_title=\"An√°lisis de Ping√ºinos con IA\", layout=\"wide\")\n",
    "\n",
    "# T√≠tulo y descripci√≥n\n",
    "st.title(\"üêß An√°lisis de Ping√ºinos Enriquecido con IA\")\n",
    "st.write(\"Explora datos de ping√ºinos con ayuda de inteligencia artificial generativa\")\n",
    "\n",
    "# Cargamos datos\n",
    "penguins = sns.load_dataset(\"penguins\")\n",
    "penguins_clean = penguins.dropna().reset_index(drop=True)\n",
    "\n",
    "# Sidebar para filtros\n",
    "st.sidebar.header(\"Filtros\")\n",
    "selected_species = st.sidebar.multiselect(\"Especies\", penguins_clean['species'].unique(), default=penguins_clean['species'].unique())\n",
    "selected_island = st.sidebar.multiselect(\"Islas\", penguins_clean['island'].unique(), default=penguins_clean['island'].unique())\n",
    "\n",
    "# Filtramos datos\n",
    "filtered_data = penguins_clean[\n",
    "    penguins_clean['species'].isin(selected_species) &\n",
    "    penguins_clean['island'].isin(selected_island)\n",
    "]\n",
    "\n",
    "# Columnas principales\n",
    "col1, col2 = st.columns([3, 2])\n",
    "\n",
    "with col1:\n",
    "    st.header(\"Visualizaci√≥n de Datos\")\n",
    "    \n",
    "    # Selector de visualizaci√≥n\n",
    "    chart_type = st.selectbox(\n",
    "        \"Selecciona tipo de gr√°fico\", \n",
    "        [\"Scatter Plot\", \"Box Plot\", \"Violin Plot\", \"Pair Plot\"]\n",
    "    )\n",
    "    \n",
    "    # Generamos el gr√°fico seleccionado\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    if chart_type == \"Scatter Plot\":\n",
    "        sns.scatterplot(x='flipper_length_mm', y='body_mass_g', \n",
    "                        hue='species', size='bill_length_mm',\n",
    "                        sizes=(20, 200), alpha=0.8, data=filtered_data, ax=ax)\n",
    "        plt.title('Relaci√≥n entre Longitud de Aleta y Masa Corporal')\n",
    "        \n",
    "    elif chart_type == \"Box Plot\":\n",
    "        sns.boxplot(x='species', y='body_mass_g', data=filtered_data, ax=ax)\n",
    "        plt.title('Distribuci√≥n de Masa Corporal por Especie')\n",
    "        \n",
    "    elif chart_type == \"Violin Plot\":\n",
    "        sns.violinplot(x='species', y='flipper_length_mm', data=filtered_data, ax=ax)\n",
    "        plt.title('Distribuci√≥n de Longitud de Aleta por Especie')\n",
    "        \n",
    "    elif chart_type == \"Pair Plot\":\n",
    "        # Para pairplot necesitamos una figura diferente\n",
    "        plt.close(fig)\n",
    "        fig = sns.pairplot(filtered_data, hue='species', height=2.5)\n",
    "        plt.suptitle('Relaciones entre Variables por Especie', y=1.02)\n",
    "    \n",
    "    st.pyplot(fig)\n",
    "\n",
    "with col2:\n",
    "    st.header(\"An√°lisis con IA\")\n",
    "    \n",
    "    # Si el usuario selecciona una sola especie, mostramos su descripci√≥n\n",
    "    if len(selected_species) == 1:\n",
    "        st.subheader(f\"Sobre los ping√ºinos {selected_species[0]}\")\n",
    "        \n",
    "        # Aqu√≠ utilizar√≠amos la funci√≥n de generar_descripcion_especie\n",
    "        # y guardar√≠amos en cach√© el resultado para no llamar a la API cada vez\n",
    "        if \"descripciones\" not in st.session_state:\n",
    "            st.session_state.descripciones = {}\n",
    "            \n",
    "        if selected_species[0] not in st.session_state.descripciones:\n",
    "            with st.spinner(\"Generando descripci√≥n con IA...\"):\n",
    "                # Llamar√≠amos a la funci√≥n que usa OpenAI para generar la descripci√≥n\n",
    "                st.session_state.descripciones[selected_species[0]] = \"Descripci√≥n del ping√ºino...\" # Simulado\n",
    "                \n",
    "        st.write(st.session_state.descripciones[selected_species[0]])\n",
    "    \n",
    "    # Bot√≥n para generar insights sobre los datos filtrados\n",
    "    if st.button(\"Generar insights con IA\"):\n",
    "        with st.spinner(\"El modelo est√° analizando los datos...\"):\n",
    "            # Aqu√≠ llamar√≠amos a la funci√≥n que extrae insights\n",
    "            # Simulado para este ejemplo\n",
    "            insights = [\"El ping√ºino Gentoo es significativamente m√°s pesado que las otras especies\",\n",
    "                       \"Existe una fuerte correlaci√≥n entre la longitud de la aleta y la masa corporal\",\n",
    "                       \"La distribuci√≥n de especies var√≠a considerablemente seg√∫n la isla\"]\n",
    "            \n",
    "            for insight in insights:\n",
    "                st.info(insight)\n",
    "    \n",
    "    # Cuadro de texto para preguntas del usuario\n",
    "    st.subheader(\"Pregunta sobre los datos\")\n",
    "    user_question = st.text_input(\"Haz una pregunta sobre los ping√ºinos:\")\n",
    "    \n",
    "    if user_question:\n",
    "        with st.spinner(\"Procesando tu pregunta...\"):\n",
    "            # Aqu√≠ llamar√≠amos a la API de OpenAI con el contexto de los datos\n",
    "            # Simulado para este ejemplo\n",
    "            response = \"Los ping√ºinos Gentoo tienen las aletas m√°s largas de las tres especies, con un promedio de 217mm comparado con 190mm para Adelie y 195mm para Chinstrap.\"\n",
    "            st.success(response)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåü Conclusi√≥n\n",
    "\n",
    "En este notebook hemos explorado diferentes formas de enriquecer datos con IA generativa:\n",
    "\n",
    "- ‚úÖ Generamos descripciones detalladas para complementar datos num√©ricos\n",
    "- ‚úÖ Clasificamos autom√°ticamente ejemplos seg√∫n sus caracter√≠sticas\n",
    "- ‚úÖ Creamos datos sint√©ticos basados en patrones existentes\n",
    "- ‚úÖ Extrajimos insights autom√°ticos a partir de estad√≠sticas\n",
    "\n",
    "Estas t√©cnicas pueden aplicarse a cualquier dominio y tipo de datos, permiti√©ndote:\n",
    "\n",
    "- üîç Descubrir patrones ocultos en tus datos\n",
    "- üöÄ Acelerar an√°lisis exploratorios\n",
    "- üí° Generar hip√≥tesis para investigaci√≥n adicional\n",
    "- üìä Crear visualizaciones y dashboards m√°s informativos\n",
    "\n",
    "### Pr√≥ximos pasos:\n",
    "- Prueba estas t√©cnicas con tus propios datasets\n",
    "- Integra estos enriquecimientos en tus flujos de an√°lisis de datos\n",
    "- Crea dashboards interactivos que combinen datos y generaci√≥n de IA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}