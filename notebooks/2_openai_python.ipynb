{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Uso de OpenAI desde Python\n",
    "\n",
    "Este notebook muestra c√≥mo conectarse a la API de OpenAI y realizar peticiones a sus modelos de IA desde Python.\n",
    "\n",
    "## ¬øQu√© aprender√°s?\n",
    "- üîå Conectar con la API de OpenAI\n",
    "- üîë Proteger tus credenciales con variables de entorno\n",
    "- üìù Realizar peticiones b√°sicas a modelos como GPT-4\n",
    "- ‚öôÔ∏è Configurar par√°metros para ajustar las respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Importamos las bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos las bibliotecas necesarias (descomenta si es necesario)\n",
    "# !pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas\n",
    "import openai      # Biblioteca oficial de OpenAI\n",
    "import os          # Para acceder a variables de entorno\n",
    "from dotenv import load_dotenv  # Para cargar variables desde .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Configuraci√≥n de Credenciales\n",
    "\n",
    "### ¬øPor qu√© proteger tus credenciales?\n",
    "\n",
    "- üîí **Seguridad**: Evita exponer tu API key en el c√≥digo\n",
    "- üí∞ **Costos**: Previene uso no autorizado que podr√≠a generar gastos\n",
    "- üß∞ **Portabilidad**: Facilita compartir c√≥digo sin exponer informaci√≥n sensible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key cargada correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Cargamos las variables de entorno desde el archivo .env\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "# Obtenemos la API key desde las variables de entorno\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Verificamos que la API key est√© disponible\n",
    "if api_key is None or api_key == \"tu_api_key_aqui\":\n",
    "    print(\"‚ö†Ô∏è ERROR: API key no configurada correctamente.\")\n",
    "    print(\"Por favor, crea un archivo .env con tu OPENAI_API_KEY.\")\n",
    "else:\n",
    "    print(\"‚úÖ API key cargada correctamente.\")\n",
    "    # Configuramos la biblioteca con la API key\n",
    "    openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Modelos Disponibles\n",
    "\n",
    "OpenAI ofrece diferentes modelos con distintas capacidades y costos:\n",
    "\n",
    "- **GPT-4 Turbo** (`gpt-4-turbo`): El modelo m√°s avanzado, ideal para tareas complejas\n",
    "- **GPT-3.5 Turbo** (`gpt-3.5-turbo`): Buen equilibrio entre capacidad y costo\n",
    "- **GPT-4o** (`gpt-4o`): Modelo que combina texto e im√°genes \n",
    "\n",
    "Para ver todos los modelos disponibles y sus capacidades, puedes consultar la [documentaci√≥n oficial](https://platform.openai.com/docs/models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Ejemplo B√°sico: Generaci√≥n de Texto\n",
    "\n",
    "Veamos c√≥mo hacer una petici√≥n simple para generar texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para hacer una petici√≥n b√°sica a la API de OpenAI\n",
    "def generar_texto(prompt, modelo=\"gpt-3.5-turbo\", temperatura=0.7, max_tokens=150):\n",
    "    \"\"\"Funci√≥n para generar texto usando la API de OpenAI\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): El texto de entrada para el modelo\n",
    "        modelo (str): El modelo a utilizar\n",
    "        temperatura (float): Controla la creatividad (0.0 a 1.0)\n",
    "        max_tokens (int): Longitud m√°xima de la respuesta\n",
    "        \n",
    "    Returns:\n",
    "        str: El texto generado por el modelo\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Creamos la petici√≥n al API\n",
    "        response = openai.chat.completions.create(\n",
    "            model=modelo,                    # Modelo a utilizar\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}  # Mensaje del usuario\n",
    "            ],\n",
    "            temperature=temperatura,         # Nivel de creatividad\n",
    "            max_tokens=max_tokens           # Longitud m√°xima\n",
    "        )\n",
    "        \n",
    "        # Extraemos y devolvemos el texto generado\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error al generar texto: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Prompt:\n",
      "Explica qu√© es la inteligencia artificial en 3 frases simples.\n",
      "\n",
      "ü§ñ Respuesta:\n",
      "Error al generar texto: Error code: 401 - {'error': {'message': 'Incorrect API key provided: OPENAI_A***********************************************************************************************************************************************************************dj4A. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
     ]
    }
   ],
   "source": [
    "# Probamos la funci√≥n con un prompt simple\n",
    "prompt = \"Explica qu√© es la inteligencia artificial en 3 frases simples.\"\n",
    "\n",
    "# Generamos el texto\n",
    "respuesta = generar_texto(prompt)\n",
    "\n",
    "# Mostramos el resultado\n",
    "print(\"üìù Prompt:\")\n",
    "print(prompt)\n",
    "print(\"\\nü§ñ Respuesta:\")\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Ajustando los Par√°metros\n",
    "\n",
    "Los par√°metros nos permiten controlar c√≥mo responde el modelo. Veamos los m√°s importantes:\n",
    "\n",
    "### üå°Ô∏è Temperatura\n",
    "- Controla la **creatividad** y **aleatoriedad** de las respuestas\n",
    "- Rango: 0.0 a 1.0\n",
    "- üßä **Temperatura baja** (0.2): Respuestas m√°s deterministas y consistentes\n",
    "- üî• **Temperatura alta** (0.8): Respuestas m√°s creativas y variadas\n",
    "\n",
    "### üìè Max Tokens\n",
    "- Define la **longitud m√°xima** de la respuesta\n",
    "- 1 token ‚âà 4 caracteres o 3/4 de palabra en espa√±ol\n",
    "- Ejemplo: 150 tokens ‚âà 100-120 palabras\n",
    "\n",
    "Veamos c√≥mo afectan estos par√°metros a las respuestas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt para el experimento\n",
    "prompt = \"Dame ideas para un regalo de cumplea√±os para alguien que ama cocinar.\"\n",
    "\n",
    "# Generamos respuestas con diferentes temperaturas\n",
    "print(\"üßä TEMPERATURA BAJA (0.2) - Respuestas m√°s predecibles:\")\n",
    "print(generar_texto(prompt, temperatura=0.2))\n",
    "print(\"\\nüî• TEMPERATURA ALTA (0.9) - Respuestas m√°s creativas:\")\n",
    "print(generar_texto(prompt, temperatura=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos con diferentes longitudes\n",
    "print(\"üìè RESPUESTA CORTA (50 tokens):\")\n",
    "print(generar_texto(prompt, max_tokens=50))\n",
    "print(\"\\nüìú RESPUESTA LARGA (250 tokens):\")\n",
    "print(generar_texto(prompt, max_tokens=250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Caso Pr√°ctico: Asistente de An√°lisis de Texto\n",
    "\n",
    "Creemos un ejemplo simple de c√≥mo podr√≠amos usar la API para analizar un texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_texto(texto, tipo_analisis=\"general\"):\n",
    "    \"\"\"Analiza un texto usando la API de OpenAI\n",
    "    \n",
    "    Args:\n",
    "        texto (str): El texto a analizar\n",
    "        tipo_analisis (str): Tipo de an√°lisis (general, sentimiento, resumen)\n",
    "        \n",
    "    Returns:\n",
    "        str: El an√°lisis generado\n",
    "    \"\"\"\n",
    "    # Configuramos el prompt seg√∫n el tipo de an√°lisis\n",
    "    if tipo_analisis == \"sentimiento\":\n",
    "        instruccion = \"Analiza el sentimiento del siguiente texto. Indica si es positivo, negativo o neutral y explica por qu√© en una frase:\"\n",
    "        temperatura = 0.3  # M√°s consistente para an√°lisis\n",
    "    elif tipo_analisis == \"resumen\":\n",
    "        instruccion = \"Resume el siguiente texto en 2-3 frases manteniendo los puntos clave:\"\n",
    "        temperatura = 0.5\n",
    "    else:  # an√°lisis general\n",
    "        instruccion = \"Analiza el siguiente texto. Identifica temas principales, tono y p√∫blico objetivo en formato de lista:\"\n",
    "        temperatura = 0.7\n",
    "    \n",
    "    # Creamos la conversaci√≥n\n",
    "    mensajes = [\n",
    "        {\"role\": \"system\", \"content\": \"Eres un experto en an√°lisis de texto que proporciona insights claros y concisos.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{instruccion}\\n\\n{texto}\"}\n",
    "    ]\n",
    "    \n",
    "    # Obtenemos y devolvemos el an√°lisis\n",
    "    return chat_con_gpt(mensajes, temperatura=temperatura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto de ejemplo para analizar\n",
    "texto_ejemplo = \"\"\"\n",
    "Nuestra nueva l√≠nea de productos ecol√≥gicos ha superado todas las expectativas de ventas \n",
    "del primer trimestre. Los clientes valoran especialmente el compromiso con la sostenibilidad \n",
    "y la reducci√≥n de pl√°sticos en los envases. Las rese√±as en l√≠nea muestran una satisfacci√≥n \n",
    "del 92%, aunque algunos usuarios han se√±alado que el precio es ligeramente superior a \n",
    "alternativas convencionales. Recomendamos expandir la l√≠nea con 3 nuevos productos \n",
    "antes del pr√≥ximo periodo de vacaciones.\n",
    "\"\"\"\n",
    "\n",
    "# Realizamos diferentes tipos de an√°lisis\n",
    "print(\"üîç AN√ÅLISIS GENERAL:\")\n",
    "print(analizar_texto(texto_ejemplo, \"general\"))\n",
    "print(\"\\n‚ù§Ô∏è AN√ÅLISIS DE SENTIMIENTO:\")\n",
    "print(analizar_texto(texto_ejemplo, \"sentimiento\"))\n",
    "print(\"\\nüìù RESUMEN:\")\n",
    "print(analizar_texto(texto_ejemplo, \"resumen\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåü Conclusi√≥n\n",
    "\n",
    "En este notebook hemos aprendido:\n",
    "\n",
    "- ‚úÖ C√≥mo conectarnos a la API de OpenAI desde Python\n",
    "- üîë La importancia de proteger nuestras credenciales\n",
    "- ‚öôÔ∏è C√≥mo ajustar par√°metros como temperatura y longitud\n",
    "- üí¨ C√≥mo trabajar con conversaciones en formato chat\n",
    "- üõ†Ô∏è Un caso pr√°ctico de an√°lisis de texto\n",
    "\n",
    "### Pr√≥ximos pasos:\n",
    "- Explorar modelos m√°s avanzados como GPT-4\n",
    "- Integrar estos an√°lisis en flujos de trabajo de datos\n",
    "- Combinar con herramientas de visualizaci√≥n para crear dashboards interactivos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
